{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07894357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "input_folder = r\"C:\\Users\\divya_s36xyo5\\OneDrive\\Desktop\\input images\"\n",
    "output_folder = r\"C:\\Users\\divya_s36xyo5\\OneDrive\\Desktop\\output patch\"\n",
    "patch_size = (1024,1024)\n",
    "stride = 512\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Ensure the input folder exists\n",
    "if not os.path.exists(input_folder):\n",
    "    print(f\"Error: Input folder '{input_folder}' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Iterate through files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "    # Check if the path is a file and ends with \".jpg\"\n",
    "    if os.path.isfile(file_path) and filename.lower().endswith(\".jpg\"):\n",
    "       \n",
    "        # Read the image\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        # Patch the image\n",
    "        for y in range(0, image.shape[0] - patch_size[0] + 1, stride):\n",
    "            for x in range(0, image.shape[1] - patch_size[1] + 1, stride):\n",
    "                patch = image[y:y + patch_size[0], x:x + patch_size[1]]\n",
    "                patch_filename = f\"{filename.split('.')[0]}_patch_{y}_{x}.jpg\"\n",
    "                patch_path = os.path.join(output_folder, patch_filename)\n",
    "                cv2.imwrite(patch_path, patch)\n",
    "\n",
    "print(\"Patching completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527eef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import imgaug.augmenters as iaa\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "\n",
    "def read_annotations(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    boxes = []\n",
    "    for obj in root.findall('object'):\n",
    "        box = obj.find('bndbox')\n",
    "        xmin = int(float(box.find('xmin').text))\n",
    "        ymin = int(float(box.find('ymin').text))\n",
    "        xmax = int(float(box.find('xmax').text))\n",
    "        ymax = int(float(box.find('ymax').text))\n",
    "        boxes.append(BoundingBox(x1=xmin, y1=ymin, x2=xmax, y2=ymax))\n",
    "    \n",
    "    return BoundingBoxesOnImage(boxes, shape=(1, 1, 3))\n",
    "\n",
    "\n",
    "def write_annotations(output_annotation_path, boxes):\n",
    "    root = ET.Element('annotation')\n",
    "    obj = ET.SubElement(root, 'object')\n",
    "    \n",
    "    for box in boxes.bounding_boxes:\n",
    "        obj_elem = ET.SubElement(obj, 'bndbox')\n",
    "        ET.SubElement(obj_elem, 'xmin').text = str(int(box.x1))\n",
    "        ET.SubElement(obj_elem, 'ymin').text = str(int(box.y1))\n",
    "        ET.SubElement(obj_elem, 'xmax').text = str(int(box.x2))\n",
    "        ET.SubElement(obj_elem, 'ymax').text = str(int(box.y2))\n",
    "    \n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(output_annotation_path)\n",
    "\n",
    "def augment_images(images_dir, annotations_dir, output_dir, num_augmented_per_image=5):\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.Affine(rotate=(-45, 45)),\n",
    "        iaa.Multiply((0.8, 1.2)),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 1.0))\n",
    "    ])\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for img_file in os.listdir(os.path.join(images_dir)):\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        annotation_path = os.path.join(annotations_dir, img_file.replace('.jpg', '.xml'))\n",
    "\n",
    "        # Read image and annotations\n",
    "        img = np.array(Image.open(img_path))\n",
    "        boxes = read_annotations(annotation_path)\n",
    "\n",
    "        # Augment images and annotations\n",
    "        for i in range(num_augmented_per_image):\n",
    "            augmented_img, augmented_boxes = seq(image=img, bounding_boxes=boxes)\n",
    "            augmented_img_path = os.path.join(output_dir, f\"{img_file.split('.')[0]}_aug_{i}.jpg\")\n",
    "            augmented_annotation_path = os.path.join(output_dir, f\"{img_file.split('.')[0]}_aug_{i}.xml\")\n",
    "\n",
    "            Image.fromarray(augmented_img).save(augmented_img_path)\n",
    "            write_annotations(augmented_annotation_path, augmented_boxes)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    original_images_dir = \"Original_Dataset/images\"\n",
    "    original_annotations_dir = \"Original_Dataset/annotations\"\n",
    "    augmented_output_dir = \"Augmented_Dataset\"\n",
    "\n",
    "    augment_images(original_images_dir, original_annotations_dir, augmented_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cca821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define paths to original and augmented datasets\n",
    "original_dataset_path = \"C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\Original_Dataset\"\n",
    "augmented_dataset_path = \"C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\Augmented_Dataset\"\n",
    "merged_dataset_path = \"C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\Merged_Dataset_New\"\n",
    "\n",
    "# Check if the merged dataset directory is a directory\n",
    "if not os.path.isdir(merged_dataset_path):\n",
    "    # Create a new directory for the merged dataset\n",
    "    os.makedirs(merged_dataset_path)\n",
    "    print(\"Merged dataset directory created.\")\n",
    "else:\n",
    "    print(\"Merged dataset directory already exists.\")\n",
    "\n",
    "# Copy images from the original dataset\n",
    "for root, dirs, files in os.walk(original_dataset_path):\n",
    "    for file in files:\n",
    "        src_path = os.path.join(root, file)\n",
    "        dst_path = os.path.join(merged_dataset_path, file)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "# Copy images from the augmented dataset\n",
    "shutil.copytree(augmented_dataset_path, os.path.join(merged_dataset_path, \"augmented\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b86d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def organize_images_and_annotations(Merged_Dataset_New, Organized_Dataset):\n",
    "    # Create target folders for images and annotations\n",
    "    images_folder = os.path.join(Organized_Dataset, \"images\")\n",
    "    annotations_folder = os.path.join(Organized_Dataset, \"annotations\")\n",
    "\n",
    "    os.makedirs(images_folder, exist_ok=True)\n",
    "    os.makedirs(annotations_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate through the dataset folder\n",
    "    for filename in os.listdir(Merged_Dataset_New):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Copy images to the \"images\" folder\n",
    "            shutil.copy2(os.path.join(Merged_Dataset_New, filename), os.path.join(images_folder, filename))\n",
    "            \n",
    "            # Assume corresponding annotations have the same name but with a different extension (e.g., .xml)\n",
    "            annotation_filename = os.path.splitext(filename)[0] + '.xml'\n",
    "            \n",
    "            # Check if the corresponding annotation file exists\n",
    "            if os.path.exists(os.path.join(Merged_Dataset_New, annotation_filename)):\n",
    "                # Copy annotations to the \"annotations\" folder\n",
    "                shutil.copy2(os.path.join(Merged_Dataset_New, annotation_filename), os.path.join(annotations_folder, annotation_filename))\n",
    "            else:\n",
    "                print(f\"Warning: No annotation file found for {filename}\")\n",
    "\n",
    "# Example usage\n",
    "Merged_Dataset_New = \"C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\Merged_Dataset_New\"\n",
    "Organized_Dataset = \"C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\Organized_Dataset\"\n",
    "\n",
    "organize_images_and_annotations(Merged_Dataset_New, Organized_Dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d183ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "def split_dataset(images_folder, annotations_folder, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, random_seed=42):\n",
    "    # Get lists of image files\n",
    "    image_files = [f for f in os.listdir(images_folder) if f.endswith('.jpg')]\n",
    "\n",
    "    # Split the dataset\n",
    "    train_files, test_val_files = train_test_split(image_files, test_size=(val_ratio + test_ratio), random_state=random_seed)\n",
    "    val_files, test_files = train_test_split(test_val_files, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=random_seed)\n",
    "\n",
    "    # Create directories for train, validation, and test sets\n",
    "    train_folder = os.path.join(images_folder, \"train\")\n",
    "    val_folder = os.path.join(images_folder, \"val\")\n",
    "    test_folder = os.path.join(images_folder, \"test\")\n",
    "\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(val_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    # Copy images to respective folders\n",
    "    for file in train_files:\n",
    "        shutil.copy2(os.path.join(images_folder, file), os.path.join(train_folder, file))\n",
    "        shutil.copy2(os.path.join(annotations_folder, file.replace('.jpg', '.xml')), os.path.join(train_folder, file.replace('.jpg', '.xml')))\n",
    "\n",
    "    for file in val_files:\n",
    "        shutil.copy2(os.path.join(images_folder, file), os.path.join(val_folder, file))\n",
    "        shutil.copy2(os.path.join(annotations_folder, file.replace('.jpg', '.xml')), os.path.join(val_folder, file.replace('.jpg', '.xml')))\n",
    "\n",
    "    for file in test_files:\n",
    "        shutil.copy2(os.path.join(images_folder, file), os.path.join(test_folder, file))\n",
    "        shutil.copy2(os.path.join(annotations_folder, file.replace('.jpg', '.xml')), os.path.join(test_folder, file.replace('.jpg', '.xml')))\n",
    "\n",
    "# Example usage\n",
    "images_folder = \"C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\Organized_Dataset\\\\images\"\n",
    "annotations_folder = \"C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\Organized_Dataset\\\\annotations\"\n",
    "split_dataset(images_folder, annotations_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23baded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "PATH_TO_MODEL_DIR = 'path/to/saved_model'\n",
    "PATH_TO_LABELS = 'path/to/label_map.pbtxt'\n",
    "\n",
    "model = tf.saved_model.load(PATH_TO_MODEL_DIR)\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class and its ID\n",
    "class_info = [{'name': 'sorghum_panicle', 'id': 1}]\n",
    "\n",
    "# Create label_map.pbtxt content\n",
    "label_map_content = ''\n",
    "for item in class_info:\n",
    "    label_map_content += f\"item {{\\n  id: {item['id']}\\n  name: '{item['name']}'\\n}}\\n\"\n",
    "\n",
    "# Save to label_map.pbtxt\n",
    "label_map_path = 'label_map.pbtxt'\n",
    "with open(label_map_path, 'w') as f:\n",
    "    f.write(label_map_content)\n",
    "\n",
    "print(f'Label map file saved to {label_map_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run xml_to_csv.py -i Organized_Dataset/annotations -o your_dataset/annotations/train_labels.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3895e1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Specify the directory where you want to clone the repository\n",
    "clone_directory = 'C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop'  # Replace with your desired directory\n",
    "\n",
    "# Clone the TensorFlow Models repository\n",
    "command = f'git clone https://github.com/tensorflow/models.git {clone_directory}'\n",
    "subprocess.run(command, shell=True, check=True)\n",
    "\n",
    "# Check the contents of the cloned directory\n",
    "cloned_files = os.listdir(clone_directory)\n",
    "cloned_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d0eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Specify the directory where you want to clone the repository\n",
    "clone_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop'  # Use forward slashes or double backslashes\n",
    "\n",
    "# Clone the TensorFlow Models repository\n",
    "command = f'git clone https://github.com/tensorflow/models.git {clone_directory}/models'\n",
    "subprocess.run(command, shell=True, check=True)\n",
    "\n",
    "# Check the contents of the cloned directory\n",
    "cloned_files = os.listdir(os.path.join(clone_directory, 'models'))\n",
    "cloned_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run xml_to_csv.py -i Organized_Dataset/annotations -o your_dataset/annotations/train_labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d10ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def xml_to_csv(xml_folder, csv_output):\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(xml_folder + '/*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        size = root.find('size')\n",
    "        width = int(size.find('width').text)\n",
    "        height = int(size.find('height').text)\n",
    "        for member in root.findall('object'):\n",
    "            class_name = member[0].text\n",
    "            xmin = round(float(member.find('bndbox').find('xmin').text))\n",
    "            ymin = round(float(member.find('bndbox').find('ymin').text))\n",
    "            xmax = round(float(member.find('bndbox').find('xmax').text))\n",
    "            ymax = round(float(member.find('bndbox').find('ymax').text))\n",
    "            value = (root.find('filename').text, width, height, class_name, xmin, ymin, xmax, ymax)\n",
    "            xml_list.append(value)\n",
    "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    xml_df.to_csv(csv_output, index=None)\n",
    "    print(f'Successfully converted XML to CSV. Saved as {csv_output}')\n",
    "\n",
    "# Example usage\n",
    "xml_folder = 'C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\Organized_Dataset\\\\annotations'  # Path to the folder containing XML annotations\n",
    "csv_output = 'Organized_Dataset/annotations/train_labels.csv'  # Output CSV file\n",
    "xml_to_csv(xml_folder, csv_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc892fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import imgaug.augmenters as iaa\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "\n",
    "def read_annotations(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    boxes = []\n",
    "    for obj in root.findall('object'):\n",
    "        box = obj.find('bndbox')\n",
    "        xmin = int(float(box.find('xmin').text))\n",
    "        ymin = int(float(box.find('ymin').text))\n",
    "        xmax = int(float(box.find('xmax').text))\n",
    "        ymax = int(float(box.find('ymax').text))\n",
    "        boxes.append(BoundingBox(x1=xmin, y1=ymin, x2=xmax, y2=ymax))\n",
    "\n",
    "    return BoundingBoxesOnImage(boxes, shape=(1, 1, 3))\n",
    "\n",
    "\n",
    "def write_annotations(output_annotation_path, boxes, original_size=None):\n",
    "    root = ET.Element('annotation')\n",
    "\n",
    "    # Add 'filename' element\n",
    "    filename_elem = ET.SubElement(root, 'filename')\n",
    "    filename_elem.text = os.path.basename(output_annotation_path).replace('.xml', '.jpg')\n",
    "\n",
    "    # Add 'size' element\n",
    "    size_elem = ET.SubElement(root, 'size')\n",
    "    width_elem = ET.SubElement(size_elem, 'width')\n",
    "    height_elem = ET.SubElement(size_elem, 'height')\n",
    "\n",
    "    # Populate 'width' and 'height' with original or augmented size\n",
    "    if original_size is not None:\n",
    "        width_elem.text = str(original_size[0])\n",
    "        height_elem.text = str(original_size[1])\n",
    "    else:\n",
    "        width_elem.text = str(boxes.shape[1])\n",
    "        height_elem.text = str(boxes.shape[0])\n",
    "\n",
    "    # Add bounding box elements\n",
    "    for box in boxes.bounding_boxes:\n",
    "        obj_elem = ET.SubElement(root, 'object')\n",
    "        bndbox_elem = ET.SubElement(obj_elem, 'bndbox')\n",
    "        ET.SubElement(bndbox_elem, 'xmin').text = str(int(box.x1))\n",
    "        ET.SubElement(bndbox_elem, 'ymin').text = str(int(box.y1))\n",
    "        ET.SubElement(bndbox_elem, 'xmax').text = str(int(box.x2))\n",
    "        ET.SubElement(bndbox_elem, 'ymax').text = str(int(box.y2))\n",
    "\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(output_annotation_path)\n",
    "\n",
    "def augment_images(images_dir, annotations_dir, output_dir, num_augmented_per_image=5):\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.Affine(rotate=(-45, 45)),\n",
    "        iaa.Multiply((0.8, 1.2)),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 1.0))\n",
    "    ])\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for img_file in os.listdir(os.path.join(images_dir)):\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        annotation_path = os.path.join(annotations_dir, img_file.replace('.jpg', '.xml'))\n",
    "\n",
    "        # Read image and annotations\n",
    "        img = np.array(Image.open(img_path))\n",
    "        original_size = img.shape[:2]\n",
    "        boxes = read_annotations(annotation_path)\n",
    "\n",
    "        # Augment images and annotations\n",
    "        for i in range(num_augmented_per_image):\n",
    "            augmented_img, augmented_boxes = seq(image=img, bounding_boxes=boxes)\n",
    "            augmented_img_path = os.path.join(output_dir, f\"{img_file.split('.')[0]}_aug_{i}.jpg\")\n",
    "            augmented_annotation_path = os.path.join(output_dir, f\"{img_file.split('.')[0]}_aug_{i}.xml\")\n",
    "\n",
    "            Image.fromarray(augmented_img).save(augmented_img_path)\n",
    "            write_annotations(augmented_annotation_path, augmented_boxes, original_size)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    original_images_dir = \"Original_Dataset/images\"\n",
    "    original_annotations_dir = \"Original_Dataset/annotations\"\n",
    "    augmented_output_dir = \"Augmented_Dataset\"\n",
    "\n",
    "    augment_images(original_images_dir, original_annotations_dir, augmented_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import dataset_util\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'sorghum_panicle':\n",
    "        return 1\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = tf.io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = [group.xmin / width]\n",
    "    xmaxs = [group.xmax / width]\n",
    "    ymins = [group.ymin / height]\n",
    "    ymaxs = [group.ymax / height]\n",
    "    classes_text = [group['class'].encode('utf8')]\n",
    "    classes = [class_text_to_int(group['class'])]\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "# Example usage:\n",
    "csv_input = 'Organized_Dataset/annotations/train_labels.csv'\n",
    "output_path = 'Organized_Dataset/annotations/train.record'\n",
    "image_path = 'Organized_Dataset/images'\n",
    "csv_df = pd.read_csv(csv_input)\n",
    "grouped = csv_df.groupby('filename')\n",
    "tfrecords_output = tf.io.TFRecordWriter(output_path)\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group[1], image_path)\n",
    "    tfrecords_output.write(tf_example.SerializeToString())\n",
    "tfrecords_output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041799f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m venv myenv\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install tensorflow tensorflow-addons pillow lxml matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Specify the directory where you want to clone the repository\n",
    "clone_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop'  # Use forward slashes or double backslashes\n",
    "\n",
    "# Clone the TensorFlow Models repository\n",
    "command = f'git clone https://github.com/tensorflow/models.git {clone_directory}/models'\n",
    "subprocess.run(command, shell=True, check=True)\n",
    "\n",
    "# Check the contents of the cloned directory\n",
    "cloned_files = os.listdir(os.path.join(clone_directory, 'models'))\n",
    "cloned_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3264b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Specify a different directory for cloning\n",
    "clone_directory = 'C:\\\\Users\\\\divya_s36xyo5\\\\Desktop\\\\tensorflow_models'\n",
    "\n",
    "# Clone the TensorFlow Models repository\n",
    "command = f'git clone https://github.com/tensorflow/models.git {clone_directory}'\n",
    "subprocess.run(command, shell=True, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd279841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Specify a different directory for cloning\n",
    "clone_directory = 'C:\\\\Users\\\\divya_s36xyo5\\\\Desktop\\\\tensorflow_models'\n",
    "\n",
    "# Clone the TensorFlow Models repository\n",
    "command = f'git clone https://github.com/tensorflow/models.git {clone_directory}'\n",
    "subprocess.run(command, shell=True, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc100ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import dataset_util\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'sorghum_panicle':\n",
    "        return 1\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = tf.io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = [group.xmin / width]\n",
    "    xmaxs = [group.xmax / width]\n",
    "    ymins = [group.ymin / height]\n",
    "    ymaxs = [group.ymax / height]\n",
    "    classes_text = [group['class'].encode('utf8')]\n",
    "    classes = [class_text_to_int(group['class'])]\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "# Example usage:\n",
    "csv_input = 'Organized_Dataset/annotations/train_labels.csv'\n",
    "output_path = 'Organized_Dataset/annotations/train.record'\n",
    "image_path = 'Organized_Dataset/images'\n",
    "csv_df = pd.read_csv(csv_input)\n",
    "grouped = csv_df.groupby('filename')\n",
    "tfrecords_output = tf.io.TFRecordWriter(output_path)\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group[1], image_path)\n",
    "    tfrecords_output.write(tf_example.SerializeToString())\n",
    "tfrecords_output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Clone the TensorFlow Models repository\n",
    "!git clone https://github.com/tensorflow/models.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Navigate to the Models Directory\n",
    "import os\n",
    "os.chdir(\"models/research\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compile Protobufs\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7babdbf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "# Define functions and code for creating TFRecords\n",
    "# ...\n",
    "\n",
    "# Example usage:\n",
    "csv_input = 'Organized_Dataset/annotations/train_labels.csv'\n",
    "output_path = 'Organized_Dataset/annotations/train.record'\n",
    "image_path = 'Organized_Dataset/images'\n",
    "csv_df = pd.read_csv(csv_input)\n",
    "grouped = csv_df.groupby('filename')\n",
    "tfrecords_output = tf.io.TFRecordWriter(output_path)\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group[1], image_path)\n",
    "    tfrecords_output.write(tf_example.SerializeToString())\n",
    "tfrecords_output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0404cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade numpy\n",
    "pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f14de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade NumPy\n",
    "pip install --upgrade numpy\n",
    "\n",
    "# Upgrade TensorFlow\n",
    "pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be70af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NumPy version\n",
    "pip show numpy\n",
    "\n",
    "# Check TensorFlow version\n",
    "pip show tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall tensorflow\n",
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab948a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "# Function to encode the image\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()]))\n",
    "\n",
    "# Function to create TFRecord example\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpeg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "# Example usage\n",
    "csv_input = 'Organized_Dataset/annotations/train_labels.csv'\n",
    "output_path = 'Organized_Dataset/annotations/train.record'\n",
    "image_path = 'Organized_Dataset/images'\n",
    "csv_df = pd.read_csv(csv_input)\n",
    "grouped = csv_df.groupby('filename')\n",
    "\n",
    "tfrecords_output = tf.io.TFRecordWriter(output_path)\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group[1], image_path)\n",
    "    tfrecords_output.write(tf_example.SerializeToString())\n",
    "tfrecords_output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f370e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7714cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import dataset_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\models\\\\research')\n",
    "sys.path.append('C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\models\\\\research\\\\slim')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875acb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import dataset_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec6a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename.strip()), 'rb') as fid:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename.strip())), 'rb') as fid:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295cf9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename.strip())), 'rb') as fid:\n",
    "    encoded_jpg = fid.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf1e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename.strip())), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9899fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "# Function to encode the image\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()]))\n",
    "\n",
    "\n",
    "print(f\"Image size: {image.size}\")\n",
    "\n",
    "# Function to create TFRecord example\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "    encoded_jpg = fid.read()\n",
    "encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "image = Image.open(encoded_jpg_io)\n",
    "\n",
    "print(f\"Image size: {image.size}\")\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpeg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_exampleencoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "image = Image.open(encoded_jpg_io)\n",
    "\n",
    "print(f\"Image size: {image.size}\")\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpeg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "\n",
    "# Example usage\n",
    "csv_input = 'Organized_Dataset/annotations/train_labels.csv'\n",
    "output_path = 'Organized_Dataset/annotations/train.record'\n",
    "image_path = 'Organized_Dataset/images'\n",
    "csv_df = pd.read_csv(csv_input)\n",
    "grouped = csv_df.groupby('filename')\n",
    "\n",
    "tfrecords_output = tf.io.TFRecordWriter(output_path)\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group[1], image_path)\n",
    "    tfrecords_output.write(tf_example.SerializeToString())\n",
    "tfrecords_output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename.strip())), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "\n",
    "\n",
    "print(f\"Image size: {image.size}\")\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpeg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "csv_input = 'Organized_Dataset/annotations/train_labels.csv'\n",
    "output_path = 'Organized_Dataset/annotations/train.record'\n",
    "image_path = 'Organized_Dataset/images'\n",
    "csv_df = pd.read_csv(csv_input)\n",
    "grouped = csv_df.groupby('filename')\n",
    "\n",
    "tfrecords_output = tf.io.TFRecordWriter(output_path)\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group[1], image_path)\n",
    "    tfrecords_output.write(tf_example.SerializeToString())\n",
    "tfrecords_output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "# Function to encode the image\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()]))\n",
    "\n",
    "# Function to create TFRecord example\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename.strip())), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "\n",
    "    image = Image.open(io.BytesIO(encoded_jpg))\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpeg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "# Example usage\n",
    "csv_input = 'Organized_Dataset/annotations/train_labels.csv'\n",
    "output_path = 'Organized_Dataset/annotations/train.record'\n",
    "image_path = 'Organized_Dataset/images'\n",
    "csv_df = pd.read_csv(csv_input)\n",
    "grouped = csv_df.groupby('filename')\n",
    "\n",
    "tfrecords_output = tf.io.TFRecordWriter(output_path)\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group[1], image_path)\n",
    "    tfrecords_output.write(tf_example.SerializeToString())\n",
    "tfrecords_output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef91ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "# Function to encode the image\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()]))\n",
    "\n",
    "# Function to create TFRecord example\n",
    "def create_tf_example(group, path):\n",
    "    filename = str(group.filename.iloc[0]).strip()  # Convert to string and strip\n",
    "    with tf.io.gfile.GFile(os.path.join(path, filename), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "\n",
    "    image = Image.open(io.BytesIO(encoded_jpg))\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = filename.encode('utf8')\n",
    "    image_format = b'jpeg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "# Example usage\n",
    "csv_input = 'Organized_Dataset/annotations/train_labels.csv'\n",
    "output_path = 'Organized_Dataset/annotations/train.record'\n",
    "image_path = 'Organized_Dataset/images'\n",
    "csv_df = pd.read_csv(csv_input)\n",
    "grouped = csv_df.groupby('filename')\n",
    "\n",
    "tfrecords_output = tf.io.TFRecordWriter(output_path)\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group[1], image_path)\n",
    "    tfrecords_output.write(tf_example.SerializeToString())\n",
    "tfrecords_output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccada101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "# Function to encode the image\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()]))\n",
    "\n",
    "# Function to create TFRecord example\n",
    "def create_tf_example(group, path):\n",
    "    filename = str(group.filename.iloc[0]).strip()  # Convert to string and strip\n",
    "    with tf.io.gfile.GFile(os.path.join(path, filename), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "\n",
    "    image = Image.open(io.BytesIO(encoded_jpg))\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = filename.encode('utf8')\n",
    "    image_format = b'jpeg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.iterrows():  # Assuming the DataFrame structure here\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "# Example usage\n",
    "csv_input = 'Organized_Dataset/annotations/train_labels.csv'\n",
    "output_path = 'Organized_Dataset/annotations/train.record'\n",
    "image_path = 'Organized_Dataset/images'\n",
    "csv_df = pd.read_csv(csv_input)\n",
    "\n",
    "tfrecords_output = tf.io.TFRecordWriter(output_path)\n",
    "grouped = csv_df.groupby('filename')\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group[1], image_path)\n",
    "    tfrecords_output.write(tf_example.SerializeToString())\n",
    "tfrecords_output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13f9ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(csv_df['class'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb377e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np  # Add this import for handling NaN values\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "# Function to encode the image\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()]))\n",
    "\n",
    "# Function to create TFRecord example\n",
    "def create_tf_example(group, path, class_mapping):\n",
    "    filename = str(group.filename.iloc[0]).strip()  # Convert to string and strip\n",
    "    with tf.io.gfile.GFile(os.path.join(path, filename), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "\n",
    "    image = Image.open(io.BytesIO(encoded_jpg))\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = filename.encode('utf8')\n",
    "    image_format = b'jpeg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.iterrows():\n",
    "        if pd.notna(row['class']):\n",
    "            class_label = class_mapping.get(row['class'], None)\n",
    "            if class_label is not None:\n",
    "                xmins.append(row['xmin'] / width)\n",
    "                xmaxs.append(row['xmax'] / width)\n",
    "                ymins.append(row['ymin'] / height)\n",
    "                ymaxs.append(row['ymax'] / height)\n",
    "                classes_text.append(row['class'].encode('utf8'))\n",
    "                classes.append(class_label)\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "# Example usage\n",
    "csv_input = 'Organized_Dataset/annotations/train_labels.csv'\n",
    "output_path = 'Organized_Dataset/annotations/train.record'\n",
    "image_path = 'Organized_Dataset/images'\n",
    "csv_df = pd.read_csv(csv_input)\n",
    "\n",
    "# Create a mapping for class labels\n",
    "class_mapping = {'sorghum_panicle': 1, 'other_class': 2, 'nan': 0}  # Replace 'other_class' with your desired label for other classes\n",
    "\n",
    "# Replace 'sorghum_panicle' with NaN and convert the 'class' column to numeric\n",
    "csv_df['class'] = csv_df['class'].replace('sorghum_panicle', np.nan)\n",
    "csv_df['class'] = pd.to_numeric(csv_df['class'], errors='coerce')\n",
    "\n",
    "tfrecords_output = tf.io.TFRecordWriter(output_path)\n",
    "grouped = csv_df.groupby('filename')\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group[1], image_path, class_mapping)\n",
    "    tfrecords_output.write(tf_example.SerializeToString())\n",
    "tfrecords_output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.protobuf import compiler\n",
    "from google.protobuf import descriptor_pb2\n",
    "\n",
    "def compile_proto(proto_file):\n",
    "    # Load the .proto file\n",
    "    with open(proto_file, 'r') as f:\n",
    "        proto_content = f.read()\n",
    "\n",
    "    # Create a CodeGeneratorRequest\n",
    "    request = compiler.plugin_pb2.CodeGeneratorRequest()\n",
    "    request.files.add(name=proto_file, content=proto_content.encode('utf-8'))\n",
    "\n",
    "    # Create a CodeGeneratorResponse\n",
    "    response = compiler.plugin_pb2.CodeGeneratorResponse()\n",
    "\n",
    "    # Compile the .proto file\n",
    "    compiler.main(request, response, None)\n",
    "\n",
    "    # Write the compiled output to files\n",
    "    for file_proto in response.file:\n",
    "        output_file = os.path.join('output_directory', file_proto.name)\n",
    "        with open(output_file, 'wb') as f:\n",
    "            f.write(file_proto.content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the path to the .proto file\n",
    "    proto_file_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/protos/anchor_generator.proto'\n",
    "\n",
    "    # Compile the .proto file\n",
    "    compile_proto(proto_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.protobuf import descriptor_pb2\n",
    "from google.protobuf.compiler import plugin_pb2, code_generator\n",
    "\n",
    "def compile_proto(proto_file):\n",
    "    # Load the .proto file\n",
    "    with open(proto_file, 'r') as f:\n",
    "        proto_content = f.read()\n",
    "\n",
    "    # Create a CodeGeneratorRequest\n",
    "    request = plugin_pb2.CodeGeneratorRequest()\n",
    "    request.files.add(name=proto_file, content=proto_content.encode('utf-8'))\n",
    "\n",
    "    # Create a CodeGeneratorResponse\n",
    "    response = plugin_pb2.CodeGeneratorResponse()\n",
    "\n",
    "    # Compile the .proto file\n",
    "    code_generator.run_main(request, response, None)\n",
    "\n",
    "    # Write the compiled output to files\n",
    "    for file_proto in response.file:\n",
    "        output_file = os.path.join('output_directory', file_proto.name)\n",
    "        with open(output_file, 'wb') as f:\n",
    "            f.write(file_proto.content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the path to the .proto file\n",
    "    proto_file_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/protos/anchor_generator.proto'\n",
    "\n",
    "    # Compile the .proto file\n",
    "    compile_proto(proto_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de7af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Run the protoc command to generate protobuf files\n",
    "protoc object_detection/protos/*.proto --python_out=.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aacf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%system protoc object_detection/protos/*.proto --python_out=.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2000de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac15f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b3e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.protobuf import descriptor_pb2\n",
    "from google.protobuf.compiler import plugin_pb2, code_generator\n",
    "\n",
    "def compile_proto(proto_file):\n",
    "    # Load the .proto file\n",
    "    with open(proto_file, 'r') as f:\n",
    "        proto_content = f.read()\n",
    "\n",
    "    # Create a CodeGeneratorRequest\n",
    "    request = plugin_pb2.CodeGeneratorRequest()\n",
    "    request.files.add(name=proto_file, content=proto_content.encode('utf-8'))\n",
    "\n",
    "    # Create a CodeGeneratorResponse\n",
    "    response = plugin_pb2.CodeGeneratorResponse()\n",
    "\n",
    "    # Compile the .proto file\n",
    "    code_generator.run_main(request, response, None)\n",
    "\n",
    "    # Write the compiled output to files\n",
    "    for file_proto in response.file:\n",
    "        output_file = os.path.join('output_directory', file_proto.name)\n",
    "        with open(output_file, 'wb') as f:\n",
    "            f.write(file_proto.content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the path to the .proto file\n",
    "    proto_file_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/protos/anchor_generator.proto'\n",
    "\n",
    "    # Compile the .proto file\n",
    "    compile_proto(proto_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495163bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.protobuf import descriptor_pb2\n",
    "from google.protobuf.compiler.plugin_pb2 import CodeGeneratorRequest, CodeGeneratorResponse\n",
    "from google.protobuf.compiler import code_generator\n",
    "\n",
    "def compile_proto(proto_file):\n",
    "    # Load the .proto file\n",
    "    with open(proto_file, 'r') as f:\n",
    "        proto_content = f.read()\n",
    "\n",
    "    # Create a CodeGeneratorRequest\n",
    "    request = CodeGeneratorRequest()\n",
    "    request.files.add(name=proto_file, content=proto_content.encode('utf-8'))\n",
    "\n",
    "    # Create a CodeGeneratorResponse\n",
    "    response = CodeGeneratorResponse()\n",
    "\n",
    "    # Compile the .proto file\n",
    "    code_generator.run_main(request, response, None)\n",
    "\n",
    "    # Write the compiled output to files\n",
    "    for file_proto in response.file:\n",
    "        output_file = os.path.join('output_directory', file_proto.name)\n",
    "        with open(output_file, 'wb') as f:\n",
    "            f.write(file_proto.content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the path to the .proto file\n",
    "    proto_file_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/protos/anchor_generator.proto'\n",
    "\n",
    "    # Compile the .proto file\n",
    "    compile_proto(proto_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888258c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.protobuf import descriptor_pb2\n",
    "from google.protobuf.compiler.plugin_pb2 import CodeGeneratorRequest, CodeGeneratorResponse\n",
    "\n",
    "# Import the correct module based on your protobuf version\n",
    "try:\n",
    "    from google.protobuf import code_generator as codegen\n",
    "except ImportError:\n",
    "    from google.protobuf.compiler import code_generator as codegen\n",
    "\n",
    "def compile_proto(proto_file):\n",
    "    # Load the .proto file\n",
    "    with open(proto_file, 'r') as f:\n",
    "        proto_content = f.read()\n",
    "\n",
    "    # Create a CodeGeneratorRequest\n",
    "    request = CodeGeneratorRequest()\n",
    "    request.files.add(name=proto_file, content=proto_content.encode('utf-8'))\n",
    "\n",
    "    # Create a CodeGeneratorResponse\n",
    "    response = CodeGeneratorResponse()\n",
    "\n",
    "    # Compile the .proto file\n",
    "    codegen.run_main(request, response, None)\n",
    "\n",
    "    # Write the compiled output to files\n",
    "    for file_proto in response.file:\n",
    "        output_file = os.path.join('output_directory', file_proto.name)\n",
    "        with open(output_file, 'wb') as f:\n",
    "            f.write(file_proto.content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the path to the .proto file\n",
    "    proto_file_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/protos/anchor_generator.proto'\n",
    "\n",
    "    # Compile the .proto file\n",
    "    compile_proto(proto_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af72ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def compile_proto(proto_file):\n",
    "    # Specify the output directory for generated files\n",
    "    output_directory = 'output_directory'\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Run the protoc command to generate Python files\n",
    "    subprocess.run(['protoc', f'--python_out={output_directory}', proto_file])\n",
    "\n",
    "    # Optional: Print the result of the protoc command\n",
    "    result = subprocess.run(['protoc', f'--python_out={output_directory}', proto_file], capture_output=True)\n",
    "    print(result.stdout.decode())\n",
    "    print(result.stderr.decode())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the path to the .proto file\n",
    "    proto_file_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/protos/anchor_generator.proto'\n",
    "\n",
    "    # Compile the .proto file\n",
    "    compile_proto(proto_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dfa733",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(['protoc', f'--python_out={output_directory}', proto_file], capture_output=True)\n",
    "print(result.stdout.decode())\n",
    "print(result.stderr.decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc97973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def compile_proto(proto_file):\n",
    "    # Specify the output directory for generated files\n",
    "    output_directory = 'output_directory'\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Specify the proto_path option based on the directory of the .proto file\n",
    "    proto_path = os.path.dirname(proto_file)\n",
    "\n",
    "    # Run the protoc command to generate Python files\n",
    "    subprocess.run(['protoc', f'--proto_path={proto_path}', f'--python_out={output_directory}', proto_file])\n",
    "\n",
    "    # Optional: Print the result of the protoc command\n",
    "    result = subprocess.run(['protoc', f'--proto_path={proto_path}', f'--python_out={output_directory}', proto_file], capture_output=True)\n",
    "    print(result.stdout.decode())\n",
    "    print(result.stderr.decode())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the path to the .proto file\n",
    "    proto_file_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/protos/anchor_generator.proto'\n",
    "\n",
    "    # Compile the .proto file\n",
    "    compile_proto(proto_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e85ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def compile_proto(proto_file):\n",
    "    # Specify the output directory for generated files\n",
    "    output_directory = 'output_directory'\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Specify the proto_path option based on the directory of the .proto file\n",
    "    proto_path = os.path.dirname(proto_file)\n",
    "\n",
    "    # Run the protoc command to generate Python files\n",
    "    subprocess.run(['protoc', f'--proto_path={proto_path}', f'--python_out={output_directory}', proto_file])\n",
    "\n",
    "    # Optional: Print the result of the protoc command\n",
    "    result = subprocess.run(['protoc', f'--proto_path={proto_path}', f'--python_out={output_directory}', proto_file], capture_output=True)\n",
    "    print(result.stdout.decode())\n",
    "    print(result.stderr.decode())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the path to the .proto file\n",
    "    proto_file_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/protos/anchor_generator.proto'\n",
    "\n",
    "    # Compile the .proto file\n",
    "    compile_proto(proto_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detection/protos/flexible_grid_anchor_generator.proto: File not found.\n",
    "object_detection/protos/grid_anchor_generator.proto: File not found.\n",
    "object_detection/protos/multiscale_anchor_generator.proto: File not found.\n",
    "object_detection/protos/ssd_anchor_generator.proto: File not found.\n",
    "anchor_generator.proto:6:1: Import \"object_detection/protos/flexible_grid_anchor_generator.proto\" was not found or had errors.\n",
    "anchor_generator.proto:7:1: Import \"object_detection/protos/grid_anchor_generator.proto\" was not found or had errors.\n",
    "anchor_generator.proto:8:1: Import \"object_detection/protos/multiscale_anchor_generator.proto\" was not found or had errors.\n",
    "anchor_generator.proto:9:1: Import \"object_detection/protos/ssd_anchor_generator.proto\" was not found or had errors.\n",
    "anchor_generator.proto:15:5: \"GridAnchorGenerator\" is not defined.\n",
    "anchor_generator.proto:16:5: \"SsdAnchorGenerator\" is not defined.\n",
    "anchor_generator.proto:17:5: \"MultiscaleAnchorGenerator\" is not defined.\n",
    "anchor_generator.proto:18:5: \"FlexibleGridAnchorGenerator\" is not defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1274532",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def compile_proto(proto_file, proto_paths):\n",
    "    # Specify the output directory for generated files\n",
    "    output_directory = 'output_directory'\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Run the protoc command to generate Python files\n",
    "    subprocess.run(['protoc', f'--proto_path={\",\".join(proto_paths)}', f'--python_out={output_directory}', proto_file])\n",
    "\n",
    "    # Optional: Print the result of the protoc command\n",
    "    result = subprocess.run(['protoc', f'--proto_path={\",\".join(proto_paths)}', f'--python_out={output_directory}', proto_file], capture_output=True)\n",
    "    print(result.stdout.decode())\n",
    "    print(result.stderr.decode())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the path to the main .proto file\n",
    "    proto_file_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/protos/anchor_generator.proto'\n",
    "\n",
    "    # Specify the paths to the dependency .proto files\n",
    "    proto_paths = [\n",
    "        'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/protos/',\n",
    "        # Add paths for other dependencies if needed\n",
    "    ]\n",
    "\n",
    "    # Compile the .proto file\n",
    "    compile_proto(proto_file_path, proto_paths) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed300af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Set the paths to your training script, pipeline configuration, and training directory\n",
    "train_script_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/legacy/train.py'\n",
    "pipeline_config_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/pipeline.config'  # Update with your pipeline configuration path\n",
    "training_dir = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'  # Update with your desired training output directory\n",
    "\n",
    "# Construct the command to run the training script\n",
    "command = f'python {train_script_path} --logtostderr --train_dir={training_dir} --pipeline_config_path={pipeline_config_path}'\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Add the path to the TensorFlow Models repository to the sys.path\n",
    "sys.path.append('C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research')\n",
    "\n",
    "# Command to run the training script\n",
    "command = f'python C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/legacy/train.py --logtostderr --train_dir=C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output --pipeline_config_path=C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/pipeline.config'\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Add the path to the TensorFlow Models repository to the sys.path\n",
    "sys.path.append('C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research')\n",
    "\n",
    "# Command to run the training script\n",
    "command = f'python C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/legacy/train.py --logtostderr --train_dir=C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output --pipeline_config_path=C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/pipeline.config'\n",
    "\n",
    "# Run the command and capture output and error messages\n",
    "result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "# Print the output and error messages\n",
    "print(\"=== Output ===\")\n",
    "print(result.stdout)\n",
    "print(\"\\n=== Error ===\")\n",
    "print(result.stderr)\n",
    "\n",
    "# Print the return code\n",
    "print(\"\\nReturn Code:\", result.returncode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7366c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Set the path to the TensorFlow Models repository\n",
    "models_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research'\n",
    "\n",
    "# Add the path to the Python path\n",
    "sys.path.append(models_path)\n",
    "\n",
    "# Command to run the training script\n",
    "command = f'python -m object_detection.legacy.train --logtostderr --train_dir=C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output --pipeline_config_path=C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/pipeline.config'\n",
    "\n",
    "# Run the command and capture output and error messages\n",
    "result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "# Print the output and error messages\n",
    "print(\"=== Output ===\")\n",
    "print(result.stdout)\n",
    "print(\"\\n=== Error ===\")\n",
    "print(result.stderr)\n",
    "\n",
    "# Print the return code\n",
    "print(\"\\nReturn Code:\", result.returncode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1931327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the TensorFlow Models repository\n",
    "models_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research'\n",
    "\n",
    "# Add the path to the Python path\n",
    "sys.path.append(models_path)\n",
    "\n",
    "# Run the training script using the %run magic command\n",
    "%run -m object_detection.legacy.train --logtostderr --train_dir=C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output --pipeline_config_path=C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/pipeline.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the TensorFlow Models repository\n",
    "models_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research'\n",
    "\n",
    "# Add the path to the Python path\n",
    "sys.path.append(models_path)\n",
    "\n",
    "# Run the training script using the %run magic command\n",
    "%run -m object_detection.legacy.train --train_dir=C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output --pipeline_config_path=C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/pipeline.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b70854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/legacy/train.py\n",
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "r\"\"\"Training executable for detection models.\n",
    "\n",
    "This executable is used to train DetectionModels. There are two ways of\n",
    "configuring the training job:\n",
    "\n",
    "1) A single pipeline_pb2.TrainEvalPipelineConfig configuration file\n",
    "can be specified by --pipeline_config_path.\n",
    "\n",
    "Example usage:\n",
    "    ./train \\\n",
    "        --logtostderr \\\n",
    "        --train_dir=path/to/train_dir \\\n",
    "        --pipeline_config_path=pipeline_config.pbtxt\n",
    "\n",
    "2) Three configuration files can be provided: a model_pb2.DetectionModel\n",
    "configuration file to define what type of DetectionModel is being trained, an\n",
    "input_reader_pb2.InputReader file to specify what training data will be used and\n",
    "a train_pb2.TrainConfig file to configure training parameters.\n",
    "\n",
    "Example usage:\n",
    "    ./train \\\n",
    "        --logtostderr \\\n",
    "        --train_dir=path/to/train_dir \\\n",
    "        --model_config_path=model_config.pbtxt \\\n",
    "        --train_config_path=train_config.pbtxt \\\n",
    "        --input_config_path=train_input_config.pbtxt\n",
    "\"\"\"\n",
    "\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.util.deprecation import deprecated\n",
    "\n",
    "\n",
    "from object_detection.builders import dataset_builder\n",
    "from object_detection.builders import graph_rewriter_builder\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.legacy import trainer\n",
    "from object_detection.utils import config_util\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.')\n",
    "flags.DEFINE_integer('task', 0, 'task id')\n",
    "flags.DEFINE_integer('num_clones', 1, 'Number of clones to deploy per worker.')\n",
    "flags.DEFINE_boolean('clone_on_cpu', False,\n",
    "                     'Force clones to be deployed on CPU.  Note that even if '\n",
    "                     'set to False (allowing ops to run on gpu), some ops may '\n",
    "                     'still be run on the CPU if they have no GPU kernel.')\n",
    "flags.DEFINE_integer('worker_replicas', 1, 'Number of worker+trainer '\n",
    "                     'replicas.')\n",
    "flags.DEFINE_integer('ps_tasks', 0,\n",
    "                     'Number of parameter server tasks. If None, does not use '\n",
    "                     'a parameter server.')\n",
    "flags.DEFINE_string('train_dir', '',\n",
    "                    'Directory to save the checkpoints and training summaries.')\n",
    "\n",
    "flags.DEFINE_string('pipeline_config_path', '',\n",
    "                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '\n",
    "                    'file. If provided, other configs are ignored')\n",
    "\n",
    "flags.DEFINE_string('train_config_path', '',\n",
    "                    'Path to a train_pb2.TrainConfig config file.')\n",
    "flags.DEFINE_string('input_config_path', '',\n",
    "                    'Path to an input_reader_pb2.InputReader config file.')\n",
    "flags.DEFINE_string('model_config_path', '',\n",
    "                    'Path to a model_pb2.DetectionModel config file.')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "@deprecated(None, 'Use object_detection/model_main.py.')\n",
    "def main(_):\n",
    "  assert FLAGS.train_dir, '`train_dir` is missing.'\n",
    "  if FLAGS.task == 0: tf.gfile.MakeDirs(FLAGS.train_dir)\n",
    "  if FLAGS.pipeline_config_path:\n",
    "    configs = config_util.get_configs_from_pipeline_file(\n",
    "        FLAGS.pipeline_config_path)\n",
    "    if FLAGS.task == 0:\n",
    "      tf.gfile.Copy(FLAGS.pipeline_config_path,\n",
    "                    os.path.join(FLAGS.train_dir, 'pipeline.config'),\n",
    "                    overwrite=True)\n",
    "  else:\n",
    "    configs = config_util.get_configs_from_multiple_files(\n",
    "        model_config_path=FLAGS.model_config_path,\n",
    "        train_config_path=FLAGS.train_config_path,\n",
    "        train_input_config_path=FLAGS.input_config_path)\n",
    "    if FLAGS.task == 0:\n",
    "      for name, config in [('model.config', FLAGS.model_config_path),\n",
    "                           ('train.config', FLAGS.train_config_path),\n",
    "                           ('input.config', FLAGS.input_config_path)]:\n",
    "        tf.gfile.Copy(config, os.path.join(FLAGS.train_dir, name),\n",
    "                      overwrite=True)\n",
    "\n",
    "  model_config = configs['model']\n",
    "  train_config = configs['train_config']\n",
    "  input_config = configs['train_input_config']\n",
    "\n",
    "  model_fn = functools.partial(\n",
    "      model_builder.build,\n",
    "      model_config=model_config,\n",
    "      is_training=True)\n",
    "\n",
    "  def get_next(config):\n",
    "    return dataset_builder.make_initializable_iterator(\n",
    "        dataset_builder.build(config)).get_next()\n",
    "\n",
    "  create_input_dict_fn = functools.partial(get_next, input_config)\n",
    "\n",
    "  env = json.loads(os.environ.get('TF_CONFIG', '{}'))\n",
    "  cluster_data = env.get('cluster', None)\n",
    "  cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None\n",
    "  task_data = env.get('task', None) or {'type': 'master', 'index': 0}\n",
    "  task_info = type('TaskSpec', (object,), task_data)\n",
    "\n",
    "  # Parameters for a single worker.\n",
    "  ps_tasks = 0\n",
    "  worker_replicas = 1\n",
    "  worker_job_name = 'lonely_worker'\n",
    "  task = 0\n",
    "  is_chief = True\n",
    "  master = ''\n",
    "\n",
    "  if cluster_data and 'worker' in cluster_data:\n",
    "    # Number of total worker replicas include \"worker\"s and the \"master\".\n",
    "    worker_replicas = len(cluster_data['worker']) + 1\n",
    "  if cluster_data and 'ps' in cluster_data:\n",
    "    ps_tasks = len(cluster_data['ps'])\n",
    "\n",
    "  if worker_replicas > 1 and ps_tasks < 1:\n",
    "    raise ValueError('At least 1 ps task is needed for distributed training.')\n",
    "\n",
    "  if worker_replicas >= 1 and ps_tasks > 0:\n",
    "    # Set up distributed training.\n",
    "    server = tf.train.Server(tf.train.ClusterSpec(cluster), protocol='grpc',\n",
    "                             job_name=task_info.type,\n",
    "                             task_index=task_info.index)\n",
    "    if task_info.type == 'ps':\n",
    "      server.join()\n",
    "      return\n",
    "\n",
    "    worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)\n",
    "    task = task_info.index\n",
    "    is_chief = (task_info.type == 'master')\n",
    "    master = server.target\n",
    "\n",
    "  graph_rewriter_fn = None\n",
    "  if 'graph_rewriter_config' in configs:\n",
    "    graph_rewriter_fn = graph_rewriter_builder.build(\n",
    "        configs['graph_rewriter_config'], is_training=True)\n",
    "\n",
    "  trainer.train(\n",
    "      create_input_dict_fn,\n",
    "      model_fn,\n",
    "      train_config,\n",
    "      master,\n",
    "      task,\n",
    "      FLAGS.num_clones,\n",
    "      worker_replicas,\n",
    "      FLAGS.clone_on_cpu,\n",
    "      ps_tasks,\n",
    "      worker_job_name,\n",
    "      is_chief,\n",
    "      FLAGS.train_dir,\n",
    "      graph_hook_fn=graph_rewriter_fn)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5cabe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load C:/Users/divya_s36xyo5/OneDrive/Desktop/models/research/object_detection/legacy/train.py\n",
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "r\"\"\"Training executable for detection models.\n",
    "\n",
    "This executable is used to train DetectionModels. There are two ways of\n",
    "configuring the training job:\n",
    "\n",
    "1) A single pipeline_pb2.TrainEvalPipelineConfig configuration file\n",
    "can be specified by --pipeline_config_path.\n",
    "\n",
    "Example usage:\n",
    "    ./train \\\n",
    "        --logtostderr \\\n",
    "        --train_dir=path/to/train_dir \\\n",
    "        --pipeline_config_path=pipeline_config.pbtxt\n",
    "\n",
    "2) Three configuration files can be provided: a model_pb2.DetectionModel\n",
    "configuration file to define what type of DetectionModel is being trained, an\n",
    "input_reader_pb2.InputReader file to specify what training data will be used and\n",
    "a train_pb2.TrainConfig file to configure training parameters.\n",
    "\n",
    "Example usage:\n",
    "    ./train \\\n",
    "        --logtostderr \\\n",
    "        --train_dir=path/to/train_dir \\\n",
    "        --model_config_path=model_config.pbtxt \\\n",
    "        --train_config_path=train_config.pbtxt \\\n",
    "        --input_config_path=train_input_config.pbtxt\n",
    "\"\"\"\n",
    "\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.util.deprecation import deprecated\n",
    "\n",
    "\n",
    "from object_detection.builders import dataset_builder\n",
    "from object_detection.builders import graph_rewriter_builder\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.legacy import trainer\n",
    "from object_detection.utils import config_util\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.')\n",
    "flags.DEFINE_integer('task', 0, 'task id')\n",
    "flags.DEFINE_integer('num_clones', 1, 'Number of clones to deploy per worker.')\n",
    "flags.DEFINE_boolean('clone_on_cpu', False,\n",
    "                     'Force clones to be deployed on CPU.  Note that even if '\n",
    "                     'set to False (allowing ops to run on gpu), some ops may '\n",
    "                     'still be run on the CPU if they have no GPU kernel.')\n",
    "flags.DEFINE_integer('worker_replicas', 1, 'Number of worker+trainer '\n",
    "                     'replicas.')\n",
    "flags.DEFINE_integer('ps_tasks', 0,\n",
    "                     'Number of parameter server tasks. If None, does not use '\n",
    "                     'a parameter server.')\n",
    "flags.DEFINE_string('train_dir', '',\n",
    "                    'Directory to save the checkpoints and training summaries.')\n",
    "\n",
    "flags.DEFINE_string('pipeline_config_path', '',\n",
    "                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '\n",
    "                    'file. If provided, other configs are ignored')\n",
    "\n",
    "flags.DEFINE_string('train_config_path', '',\n",
    "                    'Path to a train_pb2.TrainConfig config file.')\n",
    "flags.DEFINE_string('input_config_path', '',\n",
    "                    'Path to an input_reader_pb2.InputReader config file.')\n",
    "flags.DEFINE_string('model_config_path', '',\n",
    "                    'Path to a model_pb2.DetectionModel config file.')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "@deprecated(None, 'Use object_detection/model_main.py.')\n",
    "def main(_):\n",
    "  assert FLAGS.train_dir, '`train_dir` is missing.'\n",
    "  if FLAGS.task == 0: tf.gfile.MakeDirs(FLAGS.train_dir)\n",
    "  if FLAGS.pipeline_config_path:\n",
    "    configs = config_util.get_configs_from_pipeline_file(\n",
    "        FLAGS.pipeline_config_path)\n",
    "    if FLAGS.task == 0:\n",
    "      tf.gfile.Copy(FLAGS.pipeline_config_path,\n",
    "                    os.path.join(FLAGS.train_dir, 'pipeline.config'),\n",
    "                    overwrite=True)\n",
    "  else:\n",
    "    configs = config_util.get_configs_from_multiple_files(\n",
    "        model_config_path=FLAGS.model_config_path,\n",
    "        train_config_path=FLAGS.train_config_path,\n",
    "        train_input_config_path=FLAGS.input_config_path)\n",
    "    if FLAGS.task == 0:\n",
    "      for name, config in [('model.config', FLAGS.model_config_path),\n",
    "                           ('train.config', FLAGS.train_config_path),\n",
    "                           ('input.config', FLAGS.input_config_path)]:\n",
    "        tf.gfile.Copy(config, os.path.join(FLAGS.train_dir, name),\n",
    "                      overwrite=True)\n",
    "\n",
    "  model_config = configs['model']\n",
    "  train_config = configs['train_config']\n",
    "  input_config = configs['train_input_config']\n",
    "\n",
    "  model_fn = functools.partial(\n",
    "      model_builder.build,\n",
    "      model_config=model_config,\n",
    "      is_training=True)\n",
    "\n",
    "  def get_next(config):\n",
    "    return dataset_builder.make_initializable_iterator(\n",
    "        dataset_builder.build(config)).get_next()\n",
    "\n",
    "  create_input_dict_fn = functools.partial(get_next, input_config)\n",
    "\n",
    "  env = json.loads(os.environ.get('TF_CONFIG', '{}'))\n",
    "  cluster_data = env.get('cluster', None)\n",
    "  cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None\n",
    "  task_data = env.get('task', None) or {'type': 'master', 'index': 0}\n",
    "  task_info = type('TaskSpec', (object,), task_data)\n",
    "\n",
    "  # Parameters for a single worker.\n",
    "  ps_tasks = 0\n",
    "  worker_replicas = 1\n",
    "  worker_job_name = 'lonely_worker'\n",
    "  task = 0\n",
    "  is_chief = True\n",
    "  master = ''\n",
    "\n",
    "  if cluster_data and 'worker' in cluster_data:\n",
    "    # Number of total worker replicas include \"worker\"s and the \"master\".\n",
    "    worker_replicas = len(cluster_data['worker']) + 1\n",
    "  if cluster_data and 'ps' in cluster_data:\n",
    "    ps_tasks = len(cluster_data['ps'])\n",
    "\n",
    "  if worker_replicas > 1 and ps_tasks < 1:\n",
    "    raise ValueError('At least 1 ps task is needed for distributed training.')\n",
    "\n",
    "  if worker_replicas >= 1 and ps_tasks > 0:\n",
    "    # Set up distributed training.\n",
    "    server = tf.train.Server(tf.train.ClusterSpec(cluster), protocol='grpc',\n",
    "                             job_name=task_info.type,\n",
    "                             task_index=task_info.index)\n",
    "    if task_info.type == 'ps':\n",
    "      server.join()\n",
    "      return\n",
    "\n",
    "    worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)\n",
    "    task = task_info.index\n",
    "    is_chief = (task_info.type == 'master')\n",
    "    master = server.target\n",
    "\n",
    "  graph_rewriter_fn = None\n",
    "  if 'graph_rewriter_config' in configs:\n",
    "    graph_rewriter_fn = graph_rewriter_builder.build(\n",
    "        configs['graph_rewriter_config'], is_training=True)\n",
    "\n",
    "  trainer.train(\n",
    "      create_input_dict_fn,\n",
    "      model_fn,\n",
    "      train_config,\n",
    "      master,\n",
    "      task,\n",
    "      FLAGS.num_clones,\n",
    "      worker_replicas,\n",
    "      FLAGS.clone_on_cpu,\n",
    "      ps_tasks,\n",
    "      worker_job_name,\n",
    "      is_chief,\n",
    "      FLAGS.train_dir,\n",
    "      graph_hook_fn=graph_rewriter_fn)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fbce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bcae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f2ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Clone the TensorFlow Models repository\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Specify the direc # Replace with your desired directory\n",
    "\n",
    "# Clone the TensorFlow Models repository\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Move to the models directory\n",
    "%cd C:/Users/divya_s36xyo5/OneDrive/Desktop/models\n",
    "\n",
    "# Step 2: Install required dependencies\n",
    "\n",
    "\n",
    "# Step 4: Confirm the object_detection package is importable\n",
    "import object_detection\n",
    "\n",
    "# Step 5: Set paths and configure the model\n",
    "import functools\n",
    "import json\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.util.deprecation import deprecated\n",
    "from object_detection.builders import dataset_builder\n",
    "from object_detection.builders import graph_rewriter_builder\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.legacy import trainer\n",
    "from object_detection.utils import config_util\n",
    "\n",
    "# Set your paths here\n",
    "train_dir = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "pipeline_config_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/pipeline.config'\n",
    "\n",
    "# Step 6: Configure the model\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('train_dir', train_dir, 'Directory to save the checkpoints and training summaries.')\n",
    "flags.DEFINE_string('pipeline_config_path', pipeline_config_path, 'Path to a pipeline_pb2.TrainEvalPipelineConfig config file.')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "@deprecated(None, 'Use object_detection/model_main.py.')\n",
    "def main(_):\n",
    "    assert FLAGS.train_dir, '`train_dir` is missing.'\n",
    "    if FLAGS.task == 0: tf.gfile.MakeDirs(FLAGS.train_dir)\n",
    "    if FLAGS.pipeline_config_path:\n",
    "        configs = config_util.get_configs_from_pipeline_file(FLAGS.pipeline_config_path)\n",
    "        if FLAGS.task == 0:\n",
    "            tf.gfile.Copy(FLAGS.pipeline_config_path, os.path.join(FLAGS.train_dir, 'pipeline.config'), overwrite=True)\n",
    "    else:\n",
    "        configs = config_util.get_configs_from_multiple_files(\n",
    "            model_config_path=FLAGS.model_config_path,\n",
    "            train_config_path=FLAGS.train_config_path,\n",
    "            train_input_config_path=FLAGS.input_config_path)\n",
    "        if FLAGS.task == 0:\n",
    "            for name, config in [('model.config', FLAGS.model_config_path),\n",
    "                                ('train.config', FLAGS.train_config_path),\n",
    "                                ('input.config', FLAGS.input_config_path)]:\n",
    "                tf.gfile.Copy(config, os.path.join(FLAGS.train_dir, name), overwrite=True)\n",
    "\n",
    "    model_config = configs['model']\n",
    "    train_config = configs['train_config']\n",
    "    input_config = configs['train_input_config']\n",
    "\n",
    "    model_fn = functools.partial(\n",
    "        model_builder.build,\n",
    "        model_config=model_config,\n",
    "        is_training=True)\n",
    "\n",
    "    def get_next(config):\n",
    "        return dataset_builder.make_initializable_iterator(\n",
    "            dataset_builder.build(config)).get_next()\n",
    "\n",
    "    create_input_dict_fn = functools.partial(get_next, input_config)\n",
    "\n",
    "    env = json.loads(os.environ.get('TF_CONFIG', '{}'))\n",
    "    cluster_data = env.get('cluster', None)\n",
    "    cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None\n",
    "    task_data = env.get('task', None) or {'type': 'master', 'index': 0}\n",
    "    task_info = type('TaskSpec', (object,), task_data)\n",
    "\n",
    "    # Parameters for a single worker.\n",
    "    ps_tasks = 0\n",
    "    worker_replicas = 1\n",
    "    worker_job_name = 'lonely_worker'\n",
    "    task = 0\n",
    "    is_chief = True\n",
    "    master = ''\n",
    "\n",
    "    if cluster_data and 'worker' in cluster_data:\n",
    "        # Number of total worker replicas include \"worker\"s and the \"master\".\n",
    "        worker_replicas = len(cluster_data['worker']) + 1\n",
    "    if cluster_data and 'ps' in cluster_data:\n",
    "        ps_tasks = len(cluster_data['ps'])\n",
    "\n",
    "    if worker_replicas > 1 and ps_tasks < 1:\n",
    "        raise ValueError('At least 1 ps task is needed for distributed training.')\n",
    "\n",
    "    if worker_replicas >= 1 and ps_tasks > 0:\n",
    "        # Set up distributed training.\n",
    "        server = tf.train.Server(tf.train.ClusterSpec(cluster), protocol='grpc',\n",
    "                                job_name=task_info.type,\n",
    "                                task_index=task_info.index)\n",
    "        if task_info.type == 'ps':\n",
    "            server.join()\n",
    "            return\n",
    "\n",
    "        worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)\n",
    "    task = task_info.index\n",
    "    is_chief = (task_info.type == 'master')\n",
    "    master = server.target\n",
    "\n",
    "    graph_rewriter_fn = None\n",
    "    if 'graph_rewriter_config' in configs:\n",
    "        graph_rewriter_fn = graph_rewriter_builder.build(\n",
    "            configs['graph_rewriter_config'], is_training=True)\n",
    "\n",
    "    trainer.train(\n",
    "        create_input_dict_fn,\n",
    "        model_fn,\n",
    "        train_config,\n",
    "        master,\n",
    "        task,\n",
    "        FLAGS.num_clones,\n",
    "        worker_replicas,\n",
    "        FLAGS.clone_on_cpu,\n",
    "        ps_tasks,\n",
    "        worker_job_name,\n",
    "        is_chief,\n",
    "        FLAGS.train_dir,\n",
    "        graph_hook_fn=graph_rewriter_fn)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b32b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the path to the TensorFlow Models directory\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "\n",
    "# Set the path to your custom model directory\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "\n",
    "# Set the path to your training directory\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Set the path to the pipeline configuration file\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config')\n",
    "\n",
    "# Change the current working directory to the TensorFlow Models directory\n",
    "os.chdir(models_directory)\n",
    "\n",
    "# Train the model using the legacy train script\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir={train_directory} ' \\\n",
    "                f'--pipeline_config_path={pipeline_config_path}'\n",
    "\n",
    "subprocess.run(train_command, shell=True, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb06364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 3: Run the training command\n",
    "subprocess.run(train_command, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 3: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f256738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063396c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-object-detection-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831b277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/tensorflow/models.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99a7720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 3: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24beadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 3: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd319297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Upgrade TensorFlow\n",
    "!pip install --upgrade tensorflow\n",
    "\n",
    "# Step 3: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 4: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01964b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONPATH'] += \":/path/to/models/research:/path/to/models/research/slim\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a168cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Upgrade TensorFlow\n",
    "!pip install --upgrade tensorflow\n",
    "\n",
    "# Step 3: Replace tf.contrib.slim with tf.keras\n",
    "try:\n",
    "    slim_example_decoder = tf.contrib.slim.tfexample_decoder\n",
    "except AttributeError:\n",
    "    slim_example_decoder = tf.keras.utils.tf_utils.all_variables\n",
    "\n",
    "# Step 4: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 5: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Replace tf.contrib.slim with tf.keras\n",
    "try:\n",
    "    slim_example_decoder = tf.compat.v1.estimator.slim.tfexample_decoder\n",
    "except AttributeError:\n",
    "    slim_example_decoder = tf.keras.preprocessing.image.ImageDataGenerator  # Replace with the appropriate TensorFlow 2.x equivalent\n",
    "\n",
    "# Step 4: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 5: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f04520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Replace tf.contrib.slim with tf.keras\n",
    "try:\n",
    "    slim_example_decoder = tf.compat.v1.estimator.slim.tfexample_decoder\n",
    "except AttributeError:\n",
    "    slim_example_decoder = tf.keras.preprocessing.image.ImageDataGenerator  # Replace with the appropriate TensorFlow 2.x equivalent\n",
    "\n",
    "# Step 4: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 5: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Upgrade TensorFlow\n",
    "!pip install --upgrade tensorflow\n",
    "\n",
    "# Step 3: Replace tf.contrib.slim with tf.keras\n",
    "try:\n",
    "    slim_example_decoder = tf.contrib.slim.tfexample_decoder\n",
    "except AttributeError:\n",
    "    slim_example_decoder = keras.preprocessing.image.ImageDataGenerator  # Replace with the appropriate TensorFlow 2.x equivalent\n",
    "\n",
    "# Step 4: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 5: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Use TensorFlow 2.x-compatible modules\n",
    "# Replace the following line with the appropriate TensorFlow 2.x-compatible code\n",
    "slim_example_decoder = keras.preprocessing.image.ImageDataGenerator\n",
    "\n",
    "# Step 4: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 5: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3998113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Use TensorFlow 2.x-compatible modules\n",
    "# Replace the following line with the appropriate TensorFlow 2.x-compatible code\n",
    "slim_example_decoder = keras.preprocessing.image.ImageDataGenerator\n",
    "\n",
    "# Step 4: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 5: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589fedc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "\n",
    "# Step 3: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 4: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abd66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "from object_detection import model_lib_v2\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Create the training command using model_lib_v2\n",
    "train_command = f'python {models_directory}/research/object_detection/model_lib_v2.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 3: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e5e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Navigate to the models directory\n",
    "os.chdir(models_directory)\n",
    "\n",
    "# Step 3: Create and run the training command\n",
    "train_command = f'python research/object_detection/model_main_tf2.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fb6f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/model_main.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 3: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f2fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a56e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66793185",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/tensorflow/models.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b489d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/model_main_tf2.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 3: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02fc433",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade git+https://github.com/tensorflow/models.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d13373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection\n",
    "\n",
    "# P\n",
    "\n",
    "# List installed modules in the object_detection package\n",
    "import os\n",
    "modules_path = \"C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\models\\\\research\\\\object_detection\"\n",
    "module_names = [f[:-3] for f in os.listdir(modules_path) if f.endswith('.py')]\n",
    "print(f'Installed modules in object_detection package: {module_names}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cb62e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.vision.image_classification.efficientnet import efficientnet_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e8fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.vision.image_classification.efficientnet import efficientnet_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e293588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Clone the TensorFlow Models repository\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Specify the directory to clone the TensorFlow Models repository\n",
    "# Replace with your desired directory\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "\n",
    "# Clone the TensorFlow Models repository\n",
    "subprocess.run(['git', 'clone', 'https://github.com/tensorflow/models.git', models_directory])\n",
    "\n",
    "# Move to the models directory\n",
    "os.chdir(models_directory)\n",
    "\n",
    "# Step 2: Install required dependencies\n",
    "# You might need to install necessary dependencies using:\n",
    "# pip install -r official/requirements.txt\n",
    "\n",
    "# Step 4: Confirm the object_detection package is importable\n",
    "import object_detection\n",
    "\n",
    "# Step 5: Set paths and configure the model\n",
    "import functools\n",
    "import json\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.util.deprecation import deprecated\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.model_lib_v2 import trainer\n",
    "from object_detection.utils import config_util\n",
    "\n",
    "# Set your paths here\n",
    "train_dir = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "pipeline_config_path = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/pipeline.config'\n",
    "\n",
    "# Step 6: Configure the model\n",
    "flags = tf.compat.v1.app.flags\n",
    "flags.DEFINE_string('train_dir', train_dir, 'Directory to save the checkpoints and training summaries.')\n",
    "flags.DEFINE_string('pipeline_config_path', pipeline_config_path, 'Path to a pipeline_pb2.TrainEvalPipelineConfig config file.')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "@deprecated(None, 'Use object_detection/model_main.py.')\n",
    "def main(_):\n",
    "    assert FLAGS.train_dir, '`train_dir` is missing.'\n",
    "    if FLAGS.task == 0: tf.io.gfile.makedirs(FLAGS.train_dir)\n",
    "    if FLAGS.pipeline_config_path:\n",
    "        configs = config_util.get_configs_from_pipeline_file(FLAGS.pipeline_config_path)\n",
    "        if FLAGS.task == 0:\n",
    "            tf.io.gfile.copy(FLAGS.pipeline_config_path, os.path.join(FLAGS.train_dir, 'pipeline.config'), overwrite=True)\n",
    "    else:\n",
    "        configs = config_util.get_configs_from_multiple_files(\n",
    "            model_config_path=FLAGS.model_config_path,\n",
    "            train_config_path=FLAGS.train_config_path,\n",
    "            train_input_config_path=FLAGS.input_config_path)\n",
    "        if FLAGS.task == 0:\n",
    "            for name, config in [('model.config', FLAGS.model_config_path),\n",
    "                                ('train.config', FLAGS.train_config_path),\n",
    "                                ('input.config', FLAGS.input_config_path)]:\n",
    "                tf.io.gfile.copy(config, os.path.join(FLAGS.train_dir, name), overwrite=True)\n",
    "\n",
    "    model_config = configs['model']\n",
    "    train_config = configs['train_config']\n",
    "    input_config = configs['train_input_config']\n",
    "\n",
    "    model_fn = functools.partial(\n",
    "        model_builder.build,\n",
    "        model_config=model_config,\n",
    "        is_training=True)\n",
    "\n",
    "    def get_next(config):\n",
    "        return dataset_builder.make_initializable_iterator(\n",
    "            dataset_builder.build(config)).get_next()\n",
    "\n",
    "    create_input_dict_fn = functools.partial(get_next, input_config)\n",
    "\n",
    "    env = json.loads(os.environ.get('TF_CONFIG', '{}'))\n",
    "    cluster_data = env.get('cluster', None)\n",
    "    cluster = tf.distribute.cluster_resolver.TFConfigClusterResolver(cluster_data) if cluster_data else None\n",
    "    task_data = env.get('task', None) or {'type': 'master', 'index': 0}\n",
    "    task_info = type('TaskSpec', (object,), task_data)\n",
    "\n",
    "    # Parameters for a single worker.\n",
    "    ps_tasks = 0\n",
    "    worker_replicas = 1\n",
    "    worker_job_name = 'lonely_worker'\n",
    "    task = 0\n",
    "    is_chief = True\n",
    "    master = ''\n",
    "\n",
    "    if cluster_data and 'worker' in cluster_data:\n",
    "        # Number of total worker replicas include \"worker\"s and the \"master\".\n",
    "        worker_replicas = len(cluster_data['worker']) + 1\n",
    "    if cluster_data and 'ps' in cluster_data:\n",
    "        ps_tasks = len(cluster_data['ps'])\n",
    "\n",
    "    if worker_replicas > 1 and ps_tasks < 1:\n",
    "        raise ValueError('At least 1 ps task is needed for distributed training.')\n",
    "\n",
    "    if worker_replicas >= 1 and ps_tasks > 0:\n",
    "        # Set up distributed training.\n",
    "        server = tf.distribute.Server(cluster, protocol='grpc',\n",
    "                                job_name=task_info.type,\n",
    "                                task_index=task_info.index)\n",
    "        if task_info.type == 'ps':\n",
    "            server.join()\n",
    "            return\n",
    "\n",
    "        worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)\n",
    "    task = task_info.index\n",
    "    is_chief = (task_info.type == 'master')\n",
    "    master = server.target\n",
    "\n",
    "    graph_rewriter_fn = None\n",
    "    if 'graph_rewriter_config' in configs:\n",
    "        graph_rewriter_fn = graph_rewriter_builder.build(\n",
    "            configs['graph_rewriter_config'], is_training=True)\n",
    "\n",
    "    trainer.train(\n",
    "        create_input_dict_fn,\n",
    "        model_fn,\n",
    "        train_config,\n",
    "        master,\n",
    "        task,\n",
    "        FLAGS.num_clones,\n",
    "        worker_replicas,\n",
    "        FLAGS.clone_on_cpu,\n",
    "        ps_tasks,\n",
    "        worker_job_name,\n",
    "        is_chief,\n",
    "        FLAGS.train_dir,\n",
    "        graph_hook_fn=graph_rewriter_fn)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.compat.v1.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/model_main_tf2.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 3: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10195aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/model_main_tf2.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 3: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "# Load label map\n",
    "label_map_path = \"C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\models\\\\research\\\\object_detection\\\\data\\\\mscoco_label_map.pbtxt\"\n",
    "\n",
    "# Replace tf.gfile.GFile with tf.io.gfile.GFile\n",
    "with tf.io.gfile.GFile(label_map_path, 'r') as fid:\n",
    "    label_map_string = fid.read()\n",
    "\n",
    "label_map = label_map_util.string_int_label_map_pb2.StringIntLabelMap()\n",
    "text_format.Merge(label_map_string, label_map)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=90)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "# Load an image for inference\n",
    "image_path = 'C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\output patch\\\\DJI_0096_patch_0_0.jpg'\n",
    "image = tf.image.decode_image(tf.io.read_file(image_path))\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "# Perform inference\n",
    "detections = model(image)\n",
    "\n",
    "# Visualize the results\n",
    "image_np = image.numpy().squeeze()\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np,\n",
    "    detections['detection_boxes'][0].numpy(),\n",
    "    detections['detection_classes'][0].numpy().astype(int),\n",
    "    detections['detection_scores'][0].numpy(),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=5,\n",
    "    min_score_thresh=0.5\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image_np)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21cd7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from google.protobuf import text_format  # Add this import\n",
    "\n",
    "# Load label map\n",
    "label_map_path = \"C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\models\\\\research\\\\object_detection\\\\data\\\\mscoco_label_map.pbtxt\"\n",
    "\n",
    "# Replace tf.gfile.GFile with tf.io.gfile.GFile\n",
    "with tf.io.gfile.GFile(label_map_path, 'r') as fid:\n",
    "    label_map_string = fid.read()\n",
    "\n",
    "label_map = label_map_util.string_int_label_map_pb2.StringIntLabelMap()\n",
    "text_format.Merge(label_map_string, label_map)  # Fix here\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=90)\n",
    "category_index = label_map_util.create_category_index(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf1a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image for inference\n",
    "image_path = 'C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\output patch\\\\DJI_0096_patch_0_0.jpg'\n",
    "image = tf.image.decode_image(tf.io.read_file(image_path))\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "# Perform inference\n",
    "detections = model(image)\n",
    "\n",
    "# Convert the image tensor to a NumPy array\n",
    "image_np = tf.image.convert_image_dtype(image, dtype=tf.uint8).numpy().squeeze()\n",
    "\n",
    "# Visualize the results\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np,\n",
    "    detections['detection_boxes'][0].numpy(),\n",
    "    detections['detection_classes'][0].numpy().astype(int),\n",
    "    detections['detection_scores'][0].numpy(),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=5,\n",
    "    min_score_thresh=0.5\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "plt.imshow(image_np)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01501d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image for inference\n",
    "image_path = 'C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\output patch\\\\DJI_0096_patch_0_0.jpg'\n",
    "image = tf.image.decode_image(tf.io.read_file(image_path))\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "# Perform inference\n",
    "detections = model(image)\n",
    "\n",
    "# Convert the image tensor to a NumPy array\n",
    "image_np = tf.image.convert_image_dtype(image, dtype=tf.uint8).numpy().squeeze()\n",
    "\n",
    "# Visualize the results\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np,\n",
    "    detections['detection_boxes'][0].numpy(),\n",
    "    detections['detection_classes'][0].numpy().astype(int),\n",
    "    detections['detection_scores'][0].numpy(),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=5,\n",
    "    min_score_thresh=0.5\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "plt.imshow(image_np)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a855c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image for inference\n",
    "image_path = 'C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\output patch\\\\DJI_0096_patch_0_0.jpg'\n",
    "image = tf.image.decode_image(tf.io.read_file(image_path))\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "# Create a TensorFlow session\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    # Perform inference\n",
    "    detections = sess.run(model(image))\n",
    "\n",
    "# Convert the image tensor to a NumPy array\n",
    "image_np = tf.image.convert_image_dtype(image, dtype=tf.uint8).numpy().squeeze()\n",
    "\n",
    "# Visualize the results\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np,\n",
    "    detections['detection_boxes'][0],\n",
    "    detections['detection_classes'][0].astype(int),\n",
    "    detections['detection_scores'][0],\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=5,\n",
    "    min_score_thresh=0.5\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "plt.imshow(image_np)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c2a9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/model_main_tf2.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Print the command\n",
    "print(train_command)\n",
    "train_input_reader = {\n",
    "    'label_map_path': \"C:/Users/divya_s36xyo5/OneDrive/Desktop/label_map.pbtxt\",\n",
    "    'tf_record_input_reader': {\n",
    "        'input_path': \"C:/Users/divya_s36xyo5/OneDrive/Desktop/Organized_Dataset/annotations/train.record\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"Label Map Path: {os.path.abspath(train_input_reader['label_map_path'])}\")\n",
    "print(f\"TFRecord Input Path: {os.path.abspath(train_input_reader['tf_record_input_reader']['input_path'])}\")\n",
    "\n",
    "# Step 3: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lvis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eae390",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\divya_s36xyo5\\\\OneDrive\\\\Desktop\\\\models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Set the TensorFlow version to 1.x\n",
    "%tensorflow_version 1.x\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 3: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ab95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Set the TensorFlow version to 1.x\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Step 1: Modify path separators\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config').replace('\\\\', '/')\n",
    "\n",
    "# Step 2: Create the training command\n",
    "train_command = f'python {models_directory}/research/object_detection/legacy/train.py ' \\\n",
    "                f'--logtostderr ' \\\n",
    "                f'--train_dir=\"{train_directory}\" ' \\\n",
    "                f'--pipeline_config_path=\"{pipeline_config_path}\"'\n",
    "\n",
    "# Step 3: Run the training command and capture output\n",
    "result = subprocess.run(train_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n",
    "print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc46c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fc31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "# Set the GPU options if needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Directory paths\n",
    "models_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/models'\n",
    "custom_model_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/faster-rcnn/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8'\n",
    "train_directory = 'C:/Users/divya_s36xyo5/OneDrive/Desktop/Training_Output'\n",
    "\n",
    "# Load pipeline config\n",
    "pipeline_config_path = os.path.join(custom_model_directory, 'pipeline.config')\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config_path)\n",
    "\n",
    "# Update the config as needed\n",
    "configs['model'].ssd.num_classes = 90  # Set the number of classes\n",
    "\n",
    "# Write the updated config back to file\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(pipeline_config_path, \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)\n",
    "pipeline_config.model.ssd.num_classes = 90  # Set the number of classes\n",
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(pipeline_config_path, \"wb\") as f:\n",
    "    f.write(config_text)\n",
    "\n",
    "# Create the dataset and configure the training pipeline\n",
    "# You need to implement this part based on your dataset and model\n",
    "\n",
    "# Define your model\n",
    "model = tf.keras.Sequential([\n",
    "    # ... Define your model layers here ...\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=num_epochs)\n",
    "\n",
    "# Save the trained model\n",
    "saved_model_path = os.path.join(train_directory, 'saved_model')\n",
    "tf.saved_model.save(model, saved_model_path)\n",
    "\n",
    "# Optionally, you can convert the saved model to the TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "tflite_model = converter.convert()\n",
    "tflite_model_path = os.path.join(train_directory, 'model.tflite')\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4764145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "# Set the GPU options if needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309def29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096cd360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Your code for setting up directories and loading configuration...\n",
    "\n",
    "# No GPU-specific settings needed for CPU training\n",
    "\n",
    "# Your model and training code here...\n",
    "model = tf.keras.Sequential([\n",
    "    # ... Define your model layers here ...\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=num_epochs)\n",
    "\n",
    "# Save the trained model\n",
    "saved_model_path = os.path.join(train_directory, 'saved_model')\n",
    "tf.saved_model.save(model, saved_model_path)\n",
    "\n",
    "# Optionally, convert the saved model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "tflite_model = converter.convert()\n",
    "tflite_model_path = os.path.join(train_directory, 'model.tflite')\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b9687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4832c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
